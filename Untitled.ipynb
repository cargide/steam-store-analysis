{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb133514",
   "metadata": {},
   "source": [
    "# Intro\n",
    "placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef266d32",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb854103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library imports\n",
    "import csv\n",
    "import datetime as dt\n",
    "import json\n",
    "import os\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "# third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# customisations - ensure tables show all columns\n",
    "pd.set_option(\"max_columns\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04231777",
   "metadata": {},
   "source": [
    "# Get data\n",
    "## 1) Create list of games\n",
    "The API for SteamSpy (https://steamspy.com/api.php) can only return pages of 1000 results when the request is for 'all', so I need to loop the requests to get more than one page.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63d33ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_request(url, parameters=None):\n",
    "    \"\"\"Return json-formatted response of a get request using optional parameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : string\n",
    "    parameters : {'parameter': 'value'}\n",
    "        parameters to pass as part of get request\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    json_data\n",
    "        json-formatted response (dict-like)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url=url, params=parameters)\n",
    "    except SSLError as s:\n",
    "        print('SSL Error:', s)\n",
    "        \n",
    "        for i in range(5, 0, -1):\n",
    "            print('\\rWaiting... ({})'.format(i), end='')\n",
    "            time.sleep(1)\n",
    "        print('\\rRetrying.' + ' '*10)\n",
    "        \n",
    "        # recusively try again\n",
    "        return get_request(url, parameters)\n",
    "    \n",
    "    if response:\n",
    "        return response.json()\n",
    "    else:\n",
    "        # response is none usually means too many requests. Wait and try again \n",
    "        print('No response, waiting 10 seconds...')\n",
    "        time.sleep(10)\n",
    "        print('Retrying.')\n",
    "        return get_request(url, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4144acd9",
   "metadata": {},
   "source": [
    "To get a mangable amount of useful information, I limit the requests to 35 pages, as anything over that has to little owners to be of use.  \n",
    "Also, the columns returned by the call are not enough, so I limit the results to store the IDs and the names of the games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60746312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_pages():\n",
    "    pre_app_list=[0]*35\n",
    "    #Due to the amount of games in the Steam store, I limit the call to the 35000 more ownded games\n",
    "    for i in range(0,35):\n",
    "        url = \"https://steamspy.com/api.php?request=all&page=\"+str(i)\n",
    "        json_data = get_request(url)\n",
    "        steam_spy_all = pd.DataFrame.from_dict(json_data, orient='index')\n",
    "        pre_app_list[i] = steam_spy_all[['appid', 'name']].sort_values('appid').reset_index(drop=True)\n",
    "        \n",
    "    \n",
    "    app_list = pd.concat(pre_app_list).reset_index(drop=True)\n",
    "    return app_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3bfceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the results only the first time\n",
    "# game_list = request_pages()\n",
    "# game_list.to_csv('data/game_list.csv', index=False)\n",
    "\n",
    "# # instead read from stored csv\n",
    "game_list = pd.read_csv('data/game_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "512c912b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>Team Fortress Classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>Day of Defeat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>Deathmatch Classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>Half-Life: Opposing Force</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34995</th>\n",
       "      <td>1812930</td>\n",
       "      <td>Santhai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34996</th>\n",
       "      <td>1814060</td>\n",
       "      <td>Virus at Home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34997</th>\n",
       "      <td>1816650</td>\n",
       "      <td>Nelson and the Magic Cauldron: The Journey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34998</th>\n",
       "      <td>1828900</td>\n",
       "      <td>Stickit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34999</th>\n",
       "      <td>1835060</td>\n",
       "      <td>Christmas Celebration With Sakuya Izayoi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         appid                                        name\n",
       "0           10                              Counter-Strike\n",
       "1           20                       Team Fortress Classic\n",
       "2           30                               Day of Defeat\n",
       "3           40                          Deathmatch Classic\n",
       "4           50                   Half-Life: Opposing Force\n",
       "...        ...                                         ...\n",
       "34995  1812930                                     Santhai\n",
       "34996  1814060                               Virus at Home\n",
       "34997  1816650  Nelson and the Magic Cauldron: The Journey\n",
       "34998  1828900                                     Stickit\n",
       "34999  1835060    Christmas Celebration With Sakuya Izayoi\n",
       "\n",
       "[35000 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80502515",
   "metadata": {},
   "source": [
    "## 2) Download data from Steam\n",
    "The Steam API returns data by ID, so I will loop through the `appid` column in `game_list` to get the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f10a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_app_data(start, stop, parser, pause):\n",
    "    \"\"\"Return list of app data generated from parser.\n",
    "    \n",
    "    parser : function to handle request\n",
    "    \"\"\"\n",
    "    app_data = []\n",
    "    \n",
    "    # iterate through each row of app_list, confined by start and stop\n",
    "    for index, row in app_list[start:stop].iterrows():\n",
    "        print('Current index: {}'.format(index), end='\\r')\n",
    "        \n",
    "        appid = row['appid']\n",
    "        name = row['name']\n",
    "\n",
    "        # retrive app data for a row, handled by supplied parser, and append to list\n",
    "        data = parser(appid, name)\n",
    "        app_data.append(data)\n",
    "\n",
    "        time.sleep(pause) # prevent overloading api with requests\n",
    "    \n",
    "    return app_data\n",
    "\n",
    "\n",
    "def process_batches(parser, app_list, download_path, data_filename, index_filename,\n",
    "                    columns, begin=0, end=-1, batchsize=100, pause=1):\n",
    "    \"\"\"Process app data in batches, writing directly to file.\n",
    "    \n",
    "    parser : custom function to format request\n",
    "    app_list : dataframe of appid and name\n",
    "    download_path : path to store data\n",
    "    data_filename : filename to save app data\n",
    "    index_filename : filename to store highest index written\n",
    "    columns : column names for file\n",
    "    \n",
    "    Keyword arguments:\n",
    "    \n",
    "    begin : starting index (get from index_filename, default 0)\n",
    "    end : index to finish (defaults to end of app_list)\n",
    "    batchsize : number of apps to write in each batch (default 100)\n",
    "    pause : time to wait after each api request (defualt 1)\n",
    "    \n",
    "    returns: none\n",
    "    \"\"\"\n",
    "    print('Starting at index {}:\\n'.format(begin))\n",
    "    \n",
    "    # by default, process all apps in app_list\n",
    "    if end == -1:\n",
    "        end = len(app_list) + 1\n",
    "    \n",
    "    # generate array of batch begin and end points\n",
    "    batches = np.arange(begin, end, batchsize)\n",
    "    batches = np.append(batches, end)\n",
    "    \n",
    "    apps_written = 0\n",
    "    batch_times = []\n",
    "    \n",
    "    for i in range(len(batches) - 1):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        start = batches[i]\n",
    "        stop = batches[i+1]\n",
    "        \n",
    "        app_data = get_app_data(start, stop, parser, pause)\n",
    "        \n",
    "        rel_path = os.path.join(download_path, data_filename)\n",
    "        \n",
    "        # writing app data to file\n",
    "        with open(rel_path, 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=columns, extrasaction='ignore')\n",
    "            \n",
    "            for j in range(3,0,-1):\n",
    "                print(\"\\rAbout to write data, don't stop script! ({})\".format(j), end='')\n",
    "                time.sleep(0.5)\n",
    "            \n",
    "            writer.writerows(app_data)\n",
    "            print('\\rExported lines {}-{} to {}.'.format(start, stop-1, data_filename), end=' ')\n",
    "            \n",
    "        apps_written += len(app_data)\n",
    "        \n",
    "        idx_path = os.path.join(download_path, index_filename)\n",
    "        \n",
    "        # writing last index to file\n",
    "        with open(idx_path, 'w') as f:\n",
    "            index = stop\n",
    "            print(index, file=f)\n",
    "            \n",
    "        # logging time taken\n",
    "        end_time = time.time()\n",
    "        time_taken = end_time - start_time\n",
    "        \n",
    "        batch_times.append(time_taken)\n",
    "        mean_time = statistics.mean(batch_times)\n",
    "        \n",
    "        est_remaining = (len(batches) - i - 2) * mean_time\n",
    "        \n",
    "        remaining_td = dt.timedelta(seconds=round(est_remaining))\n",
    "        time_td = dt.timedelta(seconds=round(time_taken))\n",
    "        mean_td = dt.timedelta(seconds=round(mean_time))\n",
    "        \n",
    "        print('Batch {} time: {} (avg: {}, remaining: {})'.format(i, time_td, mean_td, remaining_td))\n",
    "            \n",
    "    print('\\nProcessing batches complete. {} apps written'.format(apps_written))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbc9b7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_index(download_path, index_filename):\n",
    "    \"\"\"Reset index in file to 0.\"\"\"\n",
    "    rel_path = os.path.join(download_path, index_filename)\n",
    "    \n",
    "    with open(rel_path, 'w') as f:\n",
    "        print(0, file=f)\n",
    "        \n",
    "\n",
    "def get_index(download_path, index_filename):\n",
    "    \"\"\"Retrieve index from file, returning 0 if file not found.\"\"\"\n",
    "    try:\n",
    "        rel_path = os.path.join(download_path, index_filename)\n",
    "\n",
    "        with open(rel_path, 'r') as f:\n",
    "            index = int(f.readline())\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        index = 0\n",
    "        \n",
    "    return index\n",
    "\n",
    "\n",
    "def prepare_data_file(download_path, filename, index, columns):\n",
    "    \"\"\"Create file and write headers if index is 0.\"\"\"\n",
    "    if index == 0:\n",
    "        rel_path = os.path.join(download_path, filename)\n",
    "\n",
    "        with open(rel_path, 'w', newline='') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=columns)\n",
    "            writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb178ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_steam_request(appid, name):\n",
    "    \"\"\"Unique parser to handle data from Steam Store API.\n",
    "    \n",
    "    Returns : json formatted data (dict-like)\n",
    "    \"\"\"\n",
    "    url = \"http://store.steampowered.com/api/appdetails/\"\n",
    "    parameters = {\"appids\": appid}\n",
    "    \n",
    "    json_data = get_request(url, parameters=parameters)\n",
    "    json_app_data = json_data[str(appid)]\n",
    "    \n",
    "    if json_app_data['success']:\n",
    "        data = json_app_data['data']\n",
    "    else:\n",
    "        data = {'name': name, 'steam_appid': appid}\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "# Set file parameters\n",
    "download_path = ''\n",
    "steam_app_data = 'steam_app_data.csv'\n",
    "steam_index = 'steam_index.txt'\n",
    "\n",
    "steam_columns = [\n",
    "    'type', 'name', 'steam_appid', 'required_age', 'is_free', 'controller_support',\n",
    "    'dlc', 'detailed_description', 'about_the_game', 'short_description', 'fullgame',\n",
    "    'supported_languages', 'header_image', 'website', 'pc_requirements', 'mac_requirements',\n",
    "    'linux_requirements', 'legal_notice', 'drm_notice', 'ext_user_account_notice',\n",
    "    'developers', 'publishers', 'demos', 'price_overview', 'packages', 'package_groups',\n",
    "    'platforms', 'metacritic', 'reviews', 'categories', 'genres', 'screenshots',\n",
    "    'movies', 'recommendations', 'achievements', 'release_date', 'support_info',\n",
    "    'background', 'content_descriptors'\n",
    "]\n",
    "\n",
    "# # Overwrites last index for demonstration (would usually store highest index so can continue across sessions)\n",
    "# reset_index(download_path, steam_index)\n",
    "\n",
    "# # Retrieve last index downloaded from file\n",
    "# index = get_index(download_path, steam_index)\n",
    "\n",
    "# # Wipe or create data file and write headers if index is 0\n",
    "# prepare_data_file(download_path, steam_app_data, index, steam_columns)\n",
    "\n",
    "# # Set end and chunksize for demonstration - remove to run through entire app list\n",
    "# process_batches(\n",
    "#     parser=parse_steam_request,\n",
    "#     game_list=game_list,\n",
    "#     download_path=download_path,\n",
    "#     data_filename=steam_app_data,\n",
    "#     index_filename=steam_index,\n",
    "#     columns=steam_columns,\n",
    "#     begin=index\n",
    "# )\n",
    "\n",
    "# process_batches(\n",
    "#     parser=parse_steam_request,\n",
    "#     game_list=game_list,\n",
    "#     download_path=download_path,\n",
    "#     data_filename=steam_app_data,\n",
    "#     index_filename=steam_index,\n",
    "#     columns=steam_columns,\n",
    "#     begin=index,\n",
    "#     end=10,\n",
    "#     batchsize=5\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3630ecc",
   "metadata": {},
   "source": [
    "## 3) Download data from SteamSpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1bc523",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at index 0:\n",
      "\n",
      "Exported lines 0-99 to steamspy_data.csv. Batch 0 time: 0:00:49 (avg: 0:00:49, remaining: 4:44:30)\n",
      "Exported lines 100-199 to steamspy_data.csv. Batch 1 time: 0:00:49 (avg: 0:00:49, remaining: 4:43:06)\n",
      "Exported lines 200-299 to steamspy_data.csv. Batch 2 time: 0:00:50 (avg: 0:00:49, remaining: 4:44:35)\n",
      "Exported lines 300-399 to steamspy_data.csv. Batch 3 time: 0:00:49 (avg: 0:00:49, remaining: 4:43:44)\n",
      "Exported lines 400-499 to steamspy_data.csv. Batch 4 time: 0:00:49 (avg: 0:00:49, remaining: 4:42:23)\n",
      "Exported lines 500-599 to steamspy_data.csv. Batch 5 time: 0:00:49 (avg: 0:00:49, remaining: 4:41:54)\n",
      "Exported lines 600-699 to steamspy_data.csv. Batch 6 time: 0:00:49 (avg: 0:00:49, remaining: 4:41:07)\n",
      "Exported lines 700-799 to steamspy_data.csv. Batch 7 time: 0:00:48 (avg: 0:00:49, remaining: 4:39:51)\n",
      "Exported lines 800-899 to steamspy_data.csv. Batch 8 time: 0:00:51 (avg: 0:00:49, remaining: 4:40:08)\n",
      "Exported lines 900-999 to steamspy_data.csv. Batch 9 time: 0:00:48 (avg: 0:00:49, remaining: 4:38:56)\n",
      "Exported lines 1000-1099 to steamspy_data.csv. Batch 10 time: 0:00:50 (avg: 0:00:49, remaining: 4:38:22)\n",
      "Exported lines 1100-1199 to steamspy_data.csv. Batch 11 time: 0:00:50 (avg: 0:00:49, remaining: 4:37:57)\n",
      "Exported lines 1200-1299 to steamspy_data.csv. Batch 12 time: 0:00:49 (avg: 0:00:49, remaining: 4:36:53)\n",
      "Exported lines 1300-1399 to steamspy_data.csv. Batch 13 time: 0:00:49 (avg: 0:00:49, remaining: 4:36:12)\n",
      "Exported lines 1400-1499 to steamspy_data.csv. Batch 14 time: 0:00:50 (avg: 0:00:49, remaining: 4:35:40)\n",
      "Exported lines 1500-1599 to steamspy_data.csv. Batch 15 time: 0:00:50 (avg: 0:00:49, remaining: 4:35:14)\n",
      "Exported lines 1600-1699 to steamspy_data.csv. Batch 16 time: 0:00:50 (avg: 0:00:49, remaining: 4:34:44)\n",
      "Exported lines 1700-1799 to steamspy_data.csv. Batch 17 time: 0:00:50 (avg: 0:00:49, remaining: 4:34:05)\n",
      "Exported lines 1800-1899 to steamspy_data.csv. Batch 18 time: 0:00:50 (avg: 0:00:49, remaining: 4:33:21)\n",
      "Exported lines 1900-1999 to steamspy_data.csv. Batch 19 time: 0:00:49 (avg: 0:00:49, remaining: 4:32:22)\n",
      "Exported lines 2000-2099 to steamspy_data.csv. Batch 20 time: 0:00:49 (avg: 0:00:49, remaining: 4:31:35)\n",
      "Exported lines 2100-2199 to steamspy_data.csv. Batch 21 time: 0:00:50 (avg: 0:00:49, remaining: 4:30:53)\n",
      "Exported lines 2200-2299 to steamspy_data.csv. Batch 22 time: 0:00:50 (avg: 0:00:49, remaining: 4:30:13)\n",
      "Exported lines 2300-2399 to steamspy_data.csv. Batch 23 time: 0:00:50 (avg: 0:00:49, remaining: 4:29:24)\n",
      "Exported lines 2400-2499 to steamspy_data.csv. Batch 24 time: 0:00:51 (avg: 0:00:49, remaining: 4:28:52)\n",
      "Exported lines 2500-2599 to steamspy_data.csv. Batch 25 time: 0:00:50 (avg: 0:00:49, remaining: 4:28:03)\n",
      "Exported lines 2600-2699 to steamspy_data.csv. Batch 26 time: 0:00:50 (avg: 0:00:49, remaining: 4:27:15)\n",
      "Exported lines 2700-2799 to steamspy_data.csv. Batch 27 time: 0:00:50 (avg: 0:00:49, remaining: 4:26:28)\n",
      "Exported lines 2800-2899 to steamspy_data.csv. Batch 28 time: 0:00:50 (avg: 0:00:50, remaining: 4:25:46)\n",
      "Exported lines 2900-2999 to steamspy_data.csv. Batch 29 time: 0:00:51 (avg: 0:00:50, remaining: 4:25:08)\n",
      "Exported lines 3000-3099 to steamspy_data.csv. Batch 30 time: 0:00:50 (avg: 0:00:50, remaining: 4:24:18)\n",
      "Exported lines 3100-3199 to steamspy_data.csv. Batch 31 time: 0:00:49 (avg: 0:00:50, remaining: 4:23:27)\n",
      "Exported lines 3200-3299 to steamspy_data.csv. Batch 32 time: 0:00:49 (avg: 0:00:50, remaining: 4:22:34)\n",
      "Exported lines 3300-3399 to steamspy_data.csv. Batch 33 time: 0:00:50 (avg: 0:00:50, remaining: 4:21:50)\n",
      "Exported lines 3400-3499 to steamspy_data.csv. Batch 34 time: 0:00:50 (avg: 0:00:50, remaining: 4:21:04)\n",
      "Exported lines 3500-3599 to steamspy_data.csv. Batch 35 time: 0:00:49 (avg: 0:00:50, remaining: 4:20:10)\n",
      "Exported lines 3600-3699 to steamspy_data.csv. Batch 36 time: 0:00:49 (avg: 0:00:50, remaining: 4:19:16)\n",
      "Exported lines 3700-3799 to steamspy_data.csv. Batch 37 time: 0:00:50 (avg: 0:00:50, remaining: 4:18:27)\n",
      "Exported lines 3800-3899 to steamspy_data.csv. Batch 38 time: 0:00:49 (avg: 0:00:50, remaining: 4:17:36)\n",
      "Exported lines 3900-3999 to steamspy_data.csv. Batch 39 time: 0:00:50 (avg: 0:00:50, remaining: 4:16:46)\n",
      "Exported lines 4000-4099 to steamspy_data.csv. Batch 40 time: 0:00:51 (avg: 0:00:50, remaining: 4:16:07)\n",
      "Exported lines 4100-4199 to steamspy_data.csv. Batch 41 time: 0:00:50 (avg: 0:00:50, remaining: 4:15:21)\n",
      "Exported lines 4200-4299 to steamspy_data.csv. Batch 42 time: 0:00:49 (avg: 0:00:50, remaining: 4:14:31)\n",
      "Exported lines 4300-4399 to steamspy_data.csv. Batch 43 time: 0:00:50 (avg: 0:00:50, remaining: 4:13:44)\n",
      "Exported lines 4400-4499 to steamspy_data.csv. Batch 44 time: 0:00:50 (avg: 0:00:50, remaining: 4:12:57)\n",
      "Exported lines 4500-4599 to steamspy_data.csv. Batch 45 time: 0:00:50 (avg: 0:00:50, remaining: 4:12:11)\n",
      "Exported lines 4600-4699 to steamspy_data.csv. Batch 46 time: 0:00:51 (avg: 0:00:50, remaining: 4:11:30)\n",
      "Exported lines 4700-4799 to steamspy_data.csv. Batch 47 time: 0:00:50 (avg: 0:00:50, remaining: 4:10:40)\n",
      "Exported lines 4800-4899 to steamspy_data.csv. Batch 48 time: 0:00:50 (avg: 0:00:50, remaining: 4:09:50)\n",
      "Exported lines 4900-4999 to steamspy_data.csv. Batch 49 time: 0:00:50 (avg: 0:00:50, remaining: 4:09:02)\n",
      "Exported lines 5000-5099 to steamspy_data.csv. Batch 50 time: 0:00:50 (avg: 0:00:50, remaining: 4:08:14)\n",
      "Exported lines 5100-5199 to steamspy_data.csv. Batch 51 time: 0:00:49 (avg: 0:00:50, remaining: 4:07:21)\n",
      "Exported lines 5200-5299 to steamspy_data.csv. Batch 52 time: 0:00:49 (avg: 0:00:50, remaining: 4:06:30)\n",
      "Exported lines 5300-5399 to steamspy_data.csv. Batch 53 time: 0:00:49 (avg: 0:00:50, remaining: 4:05:35)\n",
      "Exported lines 5400-5499 to steamspy_data.csv. Batch 54 time: 0:00:50 (avg: 0:00:50, remaining: 4:04:47)\n",
      "Exported lines 5500-5599 to steamspy_data.csv. Batch 55 time: 0:00:49 (avg: 0:00:50, remaining: 4:03:54)\n",
      "Exported lines 5600-5699 to steamspy_data.csv. Batch 56 time: 0:00:50 (avg: 0:00:50, remaining: 4:03:05)\n",
      "Exported lines 5700-5799 to steamspy_data.csv. Batch 57 time: 0:00:49 (avg: 0:00:50, remaining: 4:02:15)\n",
      "Exported lines 5800-5899 to steamspy_data.csv. Batch 58 time: 0:00:49 (avg: 0:00:50, remaining: 4:01:23)\n",
      "Exported lines 5900-5999 to steamspy_data.csv. Batch 59 time: 0:00:50 (avg: 0:00:50, remaining: 4:00:33)\n",
      "Exported lines 6000-6099 to steamspy_data.csv. Batch 60 time: 0:00:49 (avg: 0:00:50, remaining: 3:59:42)\n",
      "Exported lines 6100-6199 to steamspy_data.csv. Batch 61 time: 0:00:50 (avg: 0:00:50, remaining: 3:58:53)\n",
      "Exported lines 6200-6299 to steamspy_data.csv. Batch 62 time: 0:00:49 (avg: 0:00:50, remaining: 3:58:02)\n",
      "Exported lines 6300-6399 to steamspy_data.csv. Batch 63 time: 0:00:49 (avg: 0:00:50, remaining: 3:57:11)\n",
      "Exported lines 6400-6499 to steamspy_data.csv. Batch 64 time: 0:00:49 (avg: 0:00:50, remaining: 3:56:21)\n",
      "Exported lines 6500-6599 to steamspy_data.csv. Batch 65 time: 0:00:49 (avg: 0:00:50, remaining: 3:55:28)\n",
      "Exported lines 6600-6699 to steamspy_data.csv. Batch 66 time: 0:00:49 (avg: 0:00:50, remaining: 3:54:38)\n",
      "Exported lines 6700-6799 to steamspy_data.csv. Batch 67 time: 0:00:50 (avg: 0:00:50, remaining: 3:53:50)\n",
      "Exported lines 6800-6899 to steamspy_data.csv. Batch 68 time: 0:00:49 (avg: 0:00:50, remaining: 3:52:58)\n",
      "Exported lines 6900-6999 to steamspy_data.csv. Batch 69 time: 0:00:50 (avg: 0:00:50, remaining: 3:52:09)\n",
      "Exported lines 7000-7099 to steamspy_data.csv. Batch 70 time: 0:00:49 (avg: 0:00:50, remaining: 3:51:18)\n",
      "Exported lines 7100-7199 to steamspy_data.csv. Batch 71 time: 0:00:50 (avg: 0:00:50, remaining: 3:50:29)\n",
      "Exported lines 7200-7299 to steamspy_data.csv. Batch 72 time: 0:00:50 (avg: 0:00:50, remaining: 3:49:40)\n",
      "Exported lines 7300-7399 to steamspy_data.csv. Batch 73 time: 0:00:49 (avg: 0:00:50, remaining: 3:48:49)\n",
      "Exported lines 7400-7499 to steamspy_data.csv. Batch 74 time: 0:00:50 (avg: 0:00:50, remaining: 3:48:00)\n",
      "Exported lines 7500-7599 to steamspy_data.csv. Batch 75 time: 0:00:50 (avg: 0:00:50, remaining: 3:47:12)\n",
      "Exported lines 7600-7699 to steamspy_data.csv. Batch 76 time: 0:00:49 (avg: 0:00:50, remaining: 3:46:21)\n",
      "Exported lines 7700-7799 to steamspy_data.csv. Batch 77 time: 0:00:50 (avg: 0:00:50, remaining: 3:45:32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported lines 7800-7899 to steamspy_data.csv. Batch 78 time: 0:00:51 (avg: 0:00:50, remaining: 3:44:47)\n",
      "Exported lines 7900-7999 to steamspy_data.csv. Batch 79 time: 0:00:52 (avg: 0:00:50, remaining: 3:44:05)\n",
      "Exported lines 8000-8099 to steamspy_data.csv. Batch 80 time: 0:00:52 (avg: 0:00:50, remaining: 3:43:22)\n",
      "Exported lines 8100-8199 to steamspy_data.csv. Batch 81 time: 0:00:50 (avg: 0:00:50, remaining: 3:42:34)\n",
      "Exported lines 8200-8299 to steamspy_data.csv. Batch 82 time: 0:00:50 (avg: 0:00:50, remaining: 3:41:44)\n",
      "Exported lines 8300-8399 to steamspy_data.csv. Batch 83 time: 0:00:49 (avg: 0:00:50, remaining: 3:40:53)\n",
      "Exported lines 8400-8499 to steamspy_data.csv. Batch 84 time: 0:00:49 (avg: 0:00:50, remaining: 3:40:02)\n",
      "Exported lines 8500-8599 to steamspy_data.csv. Batch 85 time: 0:00:49 (avg: 0:00:50, remaining: 3:39:11)\n",
      "Exported lines 8600-8699 to steamspy_data.csv. Batch 86 time: 0:00:49 (avg: 0:00:50, remaining: 3:38:21)\n",
      "Exported lines 8700-8799 to steamspy_data.csv. Batch 87 time: 0:00:50 (avg: 0:00:50, remaining: 3:37:32)\n",
      "Exported lines 8800-8899 to steamspy_data.csv. Batch 88 time: 0:00:50 (avg: 0:00:50, remaining: 3:36:43)\n",
      "Exported lines 8900-8999 to steamspy_data.csv. Batch 89 time: 0:00:49 (avg: 0:00:50, remaining: 3:35:52)\n",
      "Exported lines 9000-9099 to steamspy_data.csv. Batch 90 time: 0:00:50 (avg: 0:00:50, remaining: 3:35:03)\n",
      "Exported lines 9100-9199 to steamspy_data.csv. Batch 91 time: 0:00:50 (avg: 0:00:50, remaining: 3:34:15)\n",
      "Exported lines 9200-9299 to steamspy_data.csv. Batch 92 time: 0:00:50 (avg: 0:00:50, remaining: 3:33:25)\n",
      "Exported lines 9300-9399 to steamspy_data.csv. Batch 93 time: 0:00:49 (avg: 0:00:50, remaining: 3:32:35)\n",
      "Exported lines 9400-9499 to steamspy_data.csv. Batch 94 time: 0:00:49 (avg: 0:00:50, remaining: 3:31:43)\n",
      "Exported lines 9500-9599 to steamspy_data.csv. Batch 95 time: 0:00:49 (avg: 0:00:50, remaining: 3:30:53)\n",
      "Exported lines 9600-9699 to steamspy_data.csv. Batch 96 time: 0:00:52 (avg: 0:00:50, remaining: 3:30:09)\n",
      "Exported lines 9700-9799 to steamspy_data.csv. Batch 97 time: 0:00:50 (avg: 0:00:50, remaining: 3:29:19)\n",
      "Exported lines 9800-9899 to steamspy_data.csv. Batch 98 time: 0:00:49 (avg: 0:00:50, remaining: 3:28:29)\n",
      "Exported lines 9900-9999 to steamspy_data.csv. Batch 99 time: 0:00:50 (avg: 0:00:50, remaining: 3:27:39)\n",
      "Exported lines 10000-10099 to steamspy_data.csv. Batch 100 time: 0:00:51 (avg: 0:00:50, remaining: 3:26:52)\n",
      "Exported lines 10100-10199 to steamspy_data.csv. Batch 101 time: 0:00:51 (avg: 0:00:50, remaining: 3:26:04)\n",
      "Exported lines 10200-10299 to steamspy_data.csv. Batch 102 time: 0:00:51 (avg: 0:00:50, remaining: 3:25:17)\n",
      "Exported lines 10300-10399 to steamspy_data.csv. Batch 103 time: 0:00:51 (avg: 0:00:50, remaining: 3:24:30)\n",
      "Exported lines 10400-10499 to steamspy_data.csv. Batch 104 time: 0:00:51 (avg: 0:00:50, remaining: 3:23:44)\n",
      "Exported lines 10500-10599 to steamspy_data.csv. Batch 105 time: 0:00:51 (avg: 0:00:50, remaining: 3:22:58)\n",
      "Exported lines 10600-10699 to steamspy_data.csv. Batch 106 time: 0:00:51 (avg: 0:00:50, remaining: 3:22:11)\n",
      "Exported lines 10700-10799 to steamspy_data.csv. Batch 107 time: 0:00:52 (avg: 0:00:50, remaining: 3:21:25)\n",
      "Exported lines 10800-10899 to steamspy_data.csv. Batch 108 time: 0:00:49 (avg: 0:00:50, remaining: 3:20:34)\n",
      "Exported lines 10900-10999 to steamspy_data.csv. Batch 109 time: 0:00:46 (avg: 0:00:50, remaining: 3:19:36)\n",
      "Exported lines 11000-11099 to steamspy_data.csv. Batch 110 time: 0:00:46 (avg: 0:00:50, remaining: 3:18:37)\n",
      "Exported lines 11100-11199 to steamspy_data.csv. Batch 111 time: 0:00:48 (avg: 0:00:50, remaining: 3:17:45)\n",
      "Exported lines 11200-11299 to steamspy_data.csv. Batch 112 time: 0:00:52 (avg: 0:00:50, remaining: 3:16:59)\n",
      "Exported lines 11300-11399 to steamspy_data.csv. Batch 113 time: 0:00:50 (avg: 0:00:50, remaining: 3:16:10)\n",
      "Exported lines 11400-11499 to steamspy_data.csv. Batch 114 time: 0:00:46 (avg: 0:00:50, remaining: 3:15:12)\n",
      "Exported lines 11500-11599 to steamspy_data.csv. Batch 115 time: 0:00:46 (avg: 0:00:50, remaining: 3:14:15)\n",
      "Exported lines 11600-11699 to steamspy_data.csv. Batch 116 time: 0:00:46 (avg: 0:00:50, remaining: 3:13:18)\n",
      "Exported lines 11700-11799 to steamspy_data.csv. Batch 117 time: 0:00:46 (avg: 0:00:50, remaining: 3:12:21)\n",
      "Exported lines 11800-11899 to steamspy_data.csv. Batch 118 time: 0:00:46 (avg: 0:00:50, remaining: 3:11:25)\n",
      "Exported lines 11900-11999 to steamspy_data.csv. Batch 119 time: 0:00:46 (avg: 0:00:49, remaining: 3:10:28)\n",
      "Exported lines 12000-12099 to steamspy_data.csv. Batch 120 time: 0:00:47 (avg: 0:00:49, remaining: 3:09:33)\n",
      "Current index: 179\r"
     ]
    }
   ],
   "source": [
    "def parse_steamspy_request(appid, name):\n",
    "    \"\"\"Parser to handle SteamSpy API data.\"\"\"\n",
    "    url = \"https://steamspy.com/api.php\"\n",
    "    parameters = {\"request\": \"appdetails\", \"appid\": appid}\n",
    "    \n",
    "    json_data = get_request(url, parameters)\n",
    "    return json_data\n",
    "\n",
    "\n",
    "# set files and columns\n",
    "download_path = 'data'\n",
    "steamspy_data = 'steamspy_data.csv'\n",
    "steamspy_index = 'steamspy_index.txt'\n",
    "\n",
    "steamspy_columns = [\n",
    "    'appid', 'name', 'developer', 'publisher', 'score_rank', 'positive',\n",
    "    'negative', 'userscore', 'owners', 'average_forever', 'average_2weeks',\n",
    "    'median_forever', 'median_2weeks', 'price', 'initialprice', 'discount',\n",
    "    'languages', 'genre', 'ccu', 'tags'\n",
    "]\n",
    "\n",
    "reset_index(download_path, steamspy_index)\n",
    "index = get_index(download_path, steamspy_index)\n",
    "\n",
    "# Wipe data file if index is 0\n",
    "prepare_data_file(download_path, steamspy_data, index, steamspy_columns)\n",
    "\n",
    "process_batches(\n",
    "    parser=parse_steamspy_request,\n",
    "    app_list=app_list,\n",
    "    download_path=download_path, \n",
    "    data_filename=steamspy_data,\n",
    "    index_filename=steamspy_index,\n",
    "    columns=steamspy_columns,\n",
    "    begin=index,\n",
    "    pause=0.3\n",
    ")\n",
    "\n",
    "# process_batches(\n",
    "#     parser=parse_steamspy_request,\n",
    "#     app_list=app_list,\n",
    "#     download_path=download_path, \n",
    "#     data_filename=steamspy_data,\n",
    "#     index_filename=steamspy_index,\n",
    "#     columns=steamspy_columns,\n",
    "#     begin=index,\n",
    "#     end=20,\n",
    "#     batchsize=5,\n",
    "#     pause=0.3\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
